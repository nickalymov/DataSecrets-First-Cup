# DataSecrets-First-Cup
Решение на основе машинного обучения для прогнозирования вероятности использования промокода покупателем. 7-е место из 76 участников конкурса.

## Краткое описание
Этот проект предназначен для предсказания вероятности использования промокодов клиентами сервиса пиццерии Додо Пицца. В проекте использованы данные о заказах, промоакциях, активности пользователей и другие фичи чтобы обучить модели машинного обучения на основе градиентного бустинга и сделать предсказания из стекинга моделей.

## Структура проекта
DataSecrets-First-Cup/
│
├── data/                            # Данные для обучения и тестирования
│   ├── my_test.csv                  # Тестовые данные с добавленными признаками
│   ├── my_train.csv                 # Тренировочные данные с добавленными признаками
├── notebooks/                       # Jupyter Notebooks для анализа данных и разработки
│   ├── EDA.ipynb                    # Ноутбук для исследовательского анализа данных (Exploratory Data Analysis)
│   ├── feature_engineering.ipynb    # Ноутбук для генерации новых признаков из различных источников данных (orders, clients_promo_october, mobile_events)
│   ├── inference.ipynb              # Ноутбук для предсказания тестовых меток
├── submit/                          # Папка для хранения результатов
│   ├── submit.csv                   # Результаты предсказаний для тестовых данных
├── LICENSE                          # Лицензия
├── README.md                        # Описание проекта (данный файл)
└── requirements.txt                 # Зависимости проекта

## Резюме
Огромную роль в соревновании имеет значени создание/изменение признаков train и test, я создал 56 новых колонок для train и test
В ноутбуке использовуется стекинг моделей и усреднение их предсказаний
- XGBClassifier
- LGBMClassifier
- CatBoostClassifier
Тренировочные данные разделены на 2 стратифицированные выборки с валидацией, на каждой выборки используются 3 модели
Предсказание меток происходит через усреднение, путем оценки всех моделей на каждой выборке (всего моделей - 3*n_splits)
Подборка параметров для кажой модели происхоидит с помощью optuna

Идеи не оправдавшие ожидания
- Использование псевдо разметки (оценка тестовых результатов - извлечение n% данных с балансом меток - например баланс 1:33 (на каждый использованный промокод приходится 33 неиспользованных) - далее 33*N - с низкой вероятностью и 1*N с высокой вероятностью
- Использование стекинга попарно или одиночных предсказаний из моделей XGB, LGBM, CAT

## Лицензия
Этот проект распространяется под лицензией MIT. Подробности см. в файле LICENSE
